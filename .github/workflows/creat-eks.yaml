name: Daily Creation of EKS Cluster from Terraform
# on:
#   schedule:
#     - cron: "45 3 * * *"
#   workflow_dispatch:
on:
  push:
    branches:
      - xyz
  workflow_dispatch:

jobs:
  create-eks:
    runs-on: self-hosted
    steps:
      - name: Cleanup build folder
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Install EKSCTL
        run: |
          # for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
          ARCH=amd64
          PLATFORM=$(uname -s)_$ARCH
          
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
          
          # (Optional) Verify checksum
          curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check
          
          tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
          
          sudo install -m 0755 /tmp/eksctl /usr/local/bin && rm /tmp/eksctl
          
      - name: Install Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18' 

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.13.3
      - name: setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'
      - name: Terraform Init
        run: terraform -chdir=./terraform/eks_cluster init

      - name: Terraform Apply
        run: terraform -chdir=./terraform/eks_cluster apply -var-file=use.tfvars -auto-approve

      - name: Run IRSA creation script
        env:
          CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME }}
          REGION: ${{ secrets.AWS_REGION }}
        run: |
          cluster_name=$CLUSTER_NAME
          oidc_id=$(aws eks describe-cluster --name $cluster_name --query "cluster.identity.oidc.issuer" --output text | cut -d '/' -f 5)
          aws iam list-open-id-connect-providers | grep $oidc_id | cut -d "/" -f4
          eksctl utils associate-iam-oidc-provider --cluster $cluster_name --approve
          chmod +x ./kubernetes/utils/trust_polecy_creaton.sh
          ./kubernetes/utils/trust_polecy_creaton.sh

      - name: Adgesting kubectl context
        run: aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME }}

      - name: Verify kubectl context
        run: kubectl get nodes

      - name: Install gatewayapi
        run: |
          kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.0/standard-install.yaml
          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/release-1.4/config/crd/experimental/gateway.networking.k8s.io_tcproutes.yaml
          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/release-1.4/config/crd/experimental/gateway.networking.k8s.io_backendtlspolicies.yaml

      - name: ebs storage setup
        run: |
          # kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.29"
          kubectl apply -f ./kubernetes/utils/storageclass.yaml

      - name: Creating namespaces
        run: |
          kubectl create namespace argocd || echo "namespace argocd already exists"
          kubectl create namespace observability || echo "namespace observability already exists"
          kubectl create namespace hrms || echo "namespace hrms already exists"
          kubectl create namespace istio-gateway || echo "already exists istio-gateway"
      - name: TLS certificate
        run: |
          kubectl create secret tls cirtificate-hrms-secret --cert=./tls_keys/tls.crt --key=./tls_keys/tls.key -n istio-gateway || echo "Tls cert already exists"
      - name: ArgoCD setup
        run: |
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          kubectl apply -f ./kubernetes/utils/git.yaml
          

      - name: adding all helm charts
        run: |
          helm repo add istio https://istio-release.storage.googleapis.com/charts
          helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts
          helm repo add aws-secrets-manager https://aws.github.io/secrets-store-csi-driver-provider-aws
          helm repo add jetstack https://charts.jetstack.io
          helm repo add hrms-helm https://koteshwarchinnolla.github.io/helm-utilities/charts
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo update
      - name: postgreSql setup
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          kubectl create ns cnpg-system || echo "namespace cnpg-system already exists"
          kubectl create secret generic aws-creds --namespace cnpg-system --from-literal=ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID --from-literal=SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY || echo "secret already exists"
          kubectl apply -f https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/release-1.21/releases/cnpg-1.21.0.yaml -n cnpg-system

      - name: applying isthio helm charts
        run: |
          helm upgrade --install istio-base istio/base -n istio-system --set defaultRevision=default --create-namespace
          helm upgrade --install istiod istio/istiod -n istio-system -f ./kubernetes/values/istio-values.yaml --wait
          helm upgrade --install istio-gateway istio/gateway -n istio-gateway --create-namespace --set service.type=NodePort
          kubectl label namespace hrms istio-injection=enabled
          kubectl delete service/istio-gateway -n istio-gateway

      - name: installing csi drivers
        run: |
          # helm upgrade --install -n kube-system csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver --set syncSecret.enabled=true
          # helm upgrade --install -n kube-system secrets-provider-aws aws-secrets-manager/secrets-store-csi-driver-provider-aws --set secrets-store-csi-driver.install=false

      
      - name: Settingup certificates and gatway
        run: |
          helm upgrade --install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.15.0 --set installCRDs=true
          helm upgrade --install certified-gateway hrms-helm/certified_gateway --set gateway_service.enabled=true --set certificate.enabled=true -n istio-gateway --create-namespace

      - name: redis with helm
        run: helm upgrade --install redis hrms-helm/redis -n redis --create-namespace
      - name: postgreSql setup
        run: |
          kubectl apply -f ./kubernetes/postgreSql/postgress-cnpg-cluster.yaml -n cnpg-system --wait
          kubectl apply -f ./kubernetes/postgreSql/postgreSql-tcp.yaml -n cnpg-system --wait
          NEW_PASS="HrmAnasolDb"
          kubectl get secret postgres-cluster-app -n cnpg-system -o yaml | yq e ".data.password = \"$(echo -n $NEW_PASS | base64)\"" - | kubectl apply -f -
          POSTGRESUser=$(kubectl get secret postgres-cluster-app -n cnpg-system -o jsonpath="{.data.username}" | base64 --decode)
          POSTGRESPass=$(kubectl get secret postgres-cluster-app -n cnpg-system -o jsonpath="{.data.password}" | base64 --decode)
          POSTGRESUrl="jdbc:postgresql://postgres-cluster-rw.cnpg-system.svc.cluster.local:5432/app"
          kubectl create secret generic postgres-credentials --from-literal=POSTGRES_PASSWORD=${POSTGRESPass} --from-literal=POSTGRES_URL=${POSTGRESUrl} --from-literal=POSTGRES_USER=${POSTGRESUser} -n hrms || echo "secret already exists"


      - name: installing all the microservices with helm
        run: |
          helm upgrade --install authentication hrms-helm/hrms-microservices -f ./authentication/values.yaml --namespace hrms --create-namespace
          helm upgrade --install notifications hrms-helm/hrms-microservices -f ./Notifications/values.yaml --namespace hrms
          helm upgrade --install employee hrms-helm/hrms-microservices -f ./employee/values.yaml --namespace hrms
          helm upgrade --install chat hrms-helm/hrms-microservices -f ./Chat/values.yaml --namespace hrms
          helm upgrade --install tickets hrms-helm/hrms-microservices -f ./Tickets/values.yaml --namespace hrms
          helm upgrade --install attendance hrms-helm/hrms-microservices -f ./Attendance/values.yaml --namespace hrms
          helm upgrade --install offerletter hrms-helm/hrms-microservices -f ./OfferLetter/values.yaml --namespace hrms
          kubectl apply -f kubernetes/utils/swagger-util.yaml
          
      - name: Annotate the service accounts for accessing aws resources
        run: |
          ROLE_NAME=istiogateway
          POLICY_NAME=istio-gateway-secret
          NAMESPACE=istio-gateway
          account_id=$(aws sts get-caller-identity --query "Account" --output text)
          # kubectl annotate serviceaccount -n kube-system secrets-store-csi-driver eks.amazonaws.com/role-arn=arn:aws:iam::$account_id:role/fetch-secrets
          kubectl annotate serviceaccount -n $NAMESPACE default eks.amazonaws.com/role-arn=arn:aws:iam::$account_id:role/$ROLE_NAME

      - name: creating all the secrets for microservices
        env:
          AWS_ACCESS_KEY_ID_ROUTE53: ${{ secrets.AWS_ACCESS_KEY_ID_ROUTE53 }}
          AWS_SECRET_ACCESS_KEY_ROUTE53: ${{ secrets.AWS_SECRET_ACCESS_KEY_ROUTE53 }}
          SMTP_USERNAME: ${{ secrets.SMTP_USERNAME }}
          SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
          DB_USERNAME: ${{ secrets.DB_USERNAME }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TLS_KEY: ${{ secrets.TLS_KEY }}
          TLS_CERT: ${{ secrets.TLS_CERT }}
        run: |
          # kubectl create secret generic route53-secret --from-literal=access-key-id=$AWS_ACCESS_KEY_ID_ROUTE53 --from-literal=secret-access-key=$AWS_SECRET_ACCESS_KEY_ROUTE53 -n cert-manager || echo "secret already exists with name route53-secret"
          kubectl create secret generic auth-db-secret --from-literal=username=$DB_USERNAME --from-literal=password=$DB_PASSWORD -n hrms || echo "secret already exists with name auth-db-secret"
          kubectl create secret generic notification-db-secret --from-literal=username=$DB_USERNAME --from-literal=password=$DB_PASSWORD -n hrms || echo "secret already exists with name notification-db-secret"
          kubectl create secret generic notification-aws-secret --from-literal=smtp-username=$SMTP_USERNAME --from-literal=smtp-password=$SMTP_PASSWORD -n hrms || echo "secret already exists with name notification-aws-secret"
          kubectl create secret generic employee-db-secret --from-literal=username=$DB_USERNAME --from-literal=password=$DB_PASSWORD -n hrms || echo "secret already exists with name employee-db-secret"
          kubectl create secret generic employee-aws-access --from-literal=aws-access-key=$AWS_ACCESS_KEY_ID  --from-literal=aws-secret-key=$AWS_SECRET_ACCESS_KEY -n hrms || echo "secret already exists with name employee-aws-access"
          kubectl create secret generic tempo-s3-credentials --from-literal=access-key-id=$AWS_ACCESS_KEY_ID --from-literal=secret-access-key=$AWS_SECRET_ACCESS_KEY -n observability || echo "secret already exists with name tempo-s3-credentials"
          kubectl create secret generic aws-creds --namespace cnpg-system --from-literal=ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID --from-literal=SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY || echo "secret already exists"

      

      - name: Verifying all the deployments
        run: |
          kubectl get all -n hrms
          kubectl get all -n redis
          kubectl get all -n cert-manager

      - name: Fetch LoadBalancer Hostname
        id: get_lb
        run: |
          LB_HOST=$(kubectl get svc gateway-istio -n istio-gateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "LB_HOST=$LB_HOST" >> $GITHUB_ENV

      # - name: Http routes for monitoring
      #   run: kubectl apply -f kubernetes/utils/monitoring-routs.yaml -n monitoring


      - name: Configuring Load Balancer Hostname to Route53
        run: |
          terraform -chdir=./terraform/route53 init
          terraform -chdir=./terraform/route53 apply \
            -var="access_key=${{ secrets.AWS_ACCESS_KEY_ID_ROUTE53 }}" \
            -var="secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY_ROUTE53 }}" \
            -var="load_balencer=${{ env.LB_HOST }}" \
            -var="domine_name=${{ secrets.DOMAIN_NAME }}" \
            -auto-approve


      # - name: Observability setup
      #   run: |
      #     helm upgrade --install opentelemetry open-telemetry/opentelemetry-collector --set image.repository="otel/opentelemetry-collector-contrib" --set mode=deployment -f ./kubernetes/values/otel-collector.yaml -n observability --create-namespace
      #     helm upgrade --install otel-target-allocator open-telemetry/opentelemetry-target-allocator -n observability --create-namespace
      #     helm upgrade --install tempo grafana/tempo -f ./kubernetes/values/grafana-tempo.yaml -n observability
      #     helm upgrade --install prometheus oci://ghcr.io/prometheus-community/charts/prometheus -f ./kubernetes/values/prometheus-values.yaml -n observability --create-namespace
      #     kubectl apply -f ./kubernetes/opentelimetry/grafana.yaml -n observability
      #     kubectl apply -f ./kubernetes/opentelimetry/loki-setup.yaml -n observability
      #     kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.85.0/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml -n observability
      #     kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.85.0/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml -n observability
      #     kubectl apply -f ./kubernetes/utils/istio-telimetry.yaml
      #     kubectl apply -f ./kubernetes/utils/istio-proxyconfig.yaml
      #     kubectl apply -f ./kubernetes/utils/service-monitor-istio-sidecar.yaml
      #     kubectl apply -f ./kubernetes/utils/service-moniter-istio-control-plane.yaml
          

          
      - name: Cleanup build folder
        if: always()
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./

